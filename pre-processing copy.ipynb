{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 12 CSV files in data/prices/energy/\n",
      "Found 12 CSV files in data/prices/regulation/\n",
      "Found 12 CSV files in data/prices/reserve/\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import glob\n",
    "\n",
    "# Define the folder paths containing the CSV files\n",
    "folder_names = ['energy', 'regulation', 'reserve']\n",
    "\n",
    "# Create a dictionary to store concatenated dataframes by folder\n",
    "data = {}\n",
    "\n",
    "# Iterate over each folder path\n",
    "for folder_name in folder_names:\n",
    "    # Get a list of all CSV files in the folder\n",
    "    folder_path = 'data/prices/' + folder_name + \"/\"\n",
    "    csv_files = glob.glob(os.path.join(folder_path, \"*.csv\"))\n",
    "\n",
    "    # Check if files are found\n",
    "    if not csv_files:\n",
    "        print(f\"No CSV files found in the directory: {folder_path}\")\n",
    "        continue\n",
    "\n",
    "    print(f\"Found {len(csv_files)} CSV files in {folder_path}\")\n",
    "\n",
    "    # Create a list to store dataframes\n",
    "    dataframes = []\n",
    "\n",
    "    # Iterate over the list of CSV files\n",
    "    for file in csv_files:\n",
    "        # Read the CSV file into a dataframe\n",
    "        df = pd.read_csv(file)\n",
    "        \n",
    "        # Append the dataframe to the list\n",
    "        dataframes.append(df)\n",
    "\n",
    "    # Concatenate all dataframes into a single dataframe for the current folder\n",
    "    concatenated_df = pd.concat(dataframes, ignore_index=True)\n",
    "    \n",
    "    # Store the concatenated dataframe in the dictionary\n",
    "    data[folder_name] = concatenated_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to map periods to specific times\n",
    "period_to_time = {\n",
    "    1: \"00:00\",  2: \"00:30\", 3: \"01:00\", 4: \"01:30\", 5: \"02:00\",     6: \"02:30\",\n",
    "    7: \"03:00\",    8: \"03:30\",    9: \"04:00\",    10: \"04:30\",\n",
    "    11: \"05:00\",    12: \"05:30\",    13: \"06:00\",    14: \"06:30\",\n",
    "    15: \"07:00\",    16: \"07:30\",    17: \"08:00\",    18: \"08:30\",\n",
    "    19: \"09:00\",    20: \"09:30\",    21: \"10:00\",    22: \"10:30\",\n",
    "    23: \"11:00\",    24: \"11:30\",    25: \"12:00\",    26: \"12:30\",\n",
    "    27: \"13:00\",    28: \"13:30\",    29: \"14:00\",    30: \"14:30\",\n",
    "    31: \"15:00\",    32: \"15:30\",    33: \"16:00\",    34: \"16:30\",\n",
    "    35: \"17:00\",    36: \"17:30\",    37: \"18:00\",    38: \"18:30\",\n",
    "    39: \"19:00\",    40: \"19:30\",    41: \"20:00\",    42: \"20:30\",\n",
    "    43: \"21:00\",    44: \"21:30\",    45: \"22:00\",    46: \"22:30\",\n",
    "    47: \"23:00\",    48: \"23:30\"\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_price_df = data['energy'][['DATE', 'PERIOD', 'USEP ($/MWh)']]\n",
    "energy_price_df.columns = ['date', 'period', 'arb_energy_price']\n",
    "\n",
    "# Ensure we are working with the original dataframe\n",
    "energy_price = energy_price_df.copy()\n",
    "\n",
    "# Map the periods to times\n",
    "energy_price.loc[:, \"timestep\"] = energy_price[\"period\"].map(period_to_time)\n",
    "\n",
    "# Concatenate the date and time columns to create new labels\n",
    "energy_price.loc[:, \"Time\"] = energy_price[\"date\"] + \" \" + energy_price[\"timestep\"]\n",
    "\n",
    "energy_price = energy_price[['Time', 'arb_energy_price']].set_index(['Time'])\n",
    "\n",
    "energy_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regulation_price = data['regulation'][['DATE', 'PERIOD', 'PRICE ($/MWh)']]\n",
    "regulation_price.columns = ['date', 'period', 'reg_up_price']\n",
    "\n",
    "regulation_price['reg_down_price'] = regulation_price['reg_up_price']\n",
    "\n",
    "regulation_price.loc[:, \"timestep\"] = regulation_price[\"period\"].map(period_to_time)\n",
    "\n",
    "regulation_price.loc[:, \"Time\"] = regulation_price[\"date\"] + \" \" + regulation_price[\"timestep\"]\n",
    "\n",
    "\n",
    "regulation_price = regulation_price[['Time', 'reg_up_price', 'reg_down_price']].set_index(['Time'])\n",
    "\n",
    "regulation_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reserve_price = data['reserve'][['RESERVE GROUP', 'DATE', 'PERIOD', 'PRICE ($/MWh)']]\n",
    "reserve_price.loc[:, \"timestep\"] = reserve_price[\"PERIOD\"].map(period_to_time)\n",
    "reserve_price.loc[:, \"Time\"] = reserve_price[\"DATE\"] + \" \" + reserve_price[\"timestep\"]\n",
    "reserve_price = reserve_price[['RESERVE GROUP', 'Time', 'PRICE ($/MWh)']]\n",
    "reserve_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cons_reserve_price = reserve_price[reserve_price[\"RESERVE GROUP\"].str.contains(\"CON\")]\n",
    "cons_reserve_price.columns = ['Group', 'Time', 'cres_capacity_price']\n",
    "cons_reserve_price = cons_reserve_price.set_index(['Group','Time'])\n",
    "cons_reserve_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_reserve_price = reserve_price[reserve_price[\"RESERVE GROUP\"].str.contains(\"PRI\")]\n",
    "prim_reserve_price.columns = ['Group', 'Time', 'pres_capacity_price']\n",
    "prim_reserve_price = prim_reserve_price.set_index(['Group','Time'])\n",
    "prim_reserve_price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prim_category = 'PRIRESA'\n",
    "cons_category = 'CONRESA'\n",
    "\n",
    "merged_df = pd.merge(energy_price, regulation_price, on=\"Time\")\n",
    "merged_df = pd.merge(merged_df, prim_reserve_price.loc[prim_category], on=\"Time\")\n",
    "merged_df = pd.merge(merged_df, cons_reserve_price.loc[cons_category], on=\"Time\")\n",
    "merged_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.price_process import price_process\n",
    "dir_path = 'data/prices/'\n",
    "prim_category = 'PRIRESA'\n",
    "cons_category = 'CONRESA'\n",
    "\n",
    "price_df = price_process(dir_path, prim_category, cons_category)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "price_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
